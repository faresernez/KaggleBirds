{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from abc import ABC, abstractmethod\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.util import normalize\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_chunks(audio_file,steps_per_subtrack = 160000, sr=32000):\n",
    "    chunks = []\n",
    "    data, samplerate = librosa.load(audio_file, sr=sr)\n",
    "    track_length = data.shape[0]\n",
    "    nChunks = track_length // steps_per_subtrack\n",
    "    if (nChunks == 0): #if an audio is shorter than steps_per_subtrack, we duplicate it\n",
    "        while (data.shape[0] < steps_per_subtrack):\n",
    "            data = np.tile(data,2)\n",
    "        nChunks = 1\n",
    "    for i in range(nChunks):\n",
    "        chunks.append(data[i*steps_per_subtrack:(i+1)*steps_per_subtrack])\n",
    "    return chunks , samplerate\n",
    "\n",
    "def indices_of_top_values(values, num_top):\n",
    "    sorted_indices = sorted(range(len(values)), key=lambda i: values[i], reverse=True)\n",
    "    return sorted_indices[:num_top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(ABC):\n",
    "\n",
    "    def __init__(self,seconds = 5, sr=32000):\n",
    "\n",
    "        self.seconds = seconds\n",
    "        self.sr = sr\n",
    "        self.steps_per_subtrack = seconds*sr\n",
    "\n",
    "    def loadAudio(self,audio_file):\n",
    "        chunks , _ = audio_to_chunks(audio_file=audio_file, steps_per_subtrack=self.steps_per_subtrack, sr=self.sr)\n",
    "        return chunks\n",
    "    \n",
    "    @abstractmethod\n",
    "    def processChunk(self,chunk):\n",
    "        pass\n",
    "\n",
    "class melSpectrogram(DataProcessor):\n",
    "\n",
    "    def __init__(self,seconds, sr, n_mels, hop_length):\n",
    "\n",
    "        super().__init__(seconds, sr)\n",
    "\n",
    "        self.n_mels = n_mels\n",
    "        self.hop_length = hop_length\n",
    "        self.fmax = self.sr / 2\n",
    "        # self.tensorShape = self.processChunk(self.loadAudio('C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/unlabeled_soundscapes/460830.ogg')[0]).shape\n",
    "        self.tensorShape = (224,224)\n",
    "\n",
    "    def processChunk(self,chunk):\n",
    "        # return melspectrogram(y = chunk, sr = self.sr, n_mels = self.n_mels, hop_length = self.hop_length, fmax = self.fmax)\n",
    "        return normalize(melspectrogram(y = chunk, sr = self.sr, n_mels = self.n_mels, hop_length = self.hop_length, fmax = self.fmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxialDW(nn.Module):\n",
    "    def __init__(self, dim, mixer_kernel, dilation = 1):\n",
    "        super().__init__()\n",
    "        h, w = mixer_kernel\n",
    "        self.dw_h = nn.Conv2d(dim, dim, kernel_size=(h, 1), padding='same', groups = dim, dilation = dilation)\n",
    "        self.dw_w = nn.Conv2d(dim, dim, kernel_size=(1, w), padding='same', groups = dim, dilation = dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dw_h(x) + self.dw_w(x)\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Encoding then downsampling\"\"\"\n",
    "    def __init__(self, in_c, out_c, mixer_kernel = (7, 7)):\n",
    "        super().__init__()\n",
    "        self.dw = AxialDW(in_c, mixer_kernel = (7, 7))\n",
    "        self.bn = nn.BatchNorm2d(in_c)\n",
    "        self.pw = nn.Conv2d(in_c, out_c, kernel_size=1)\n",
    "        self.down = nn.MaxPool2d((2,2))\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = self.bn(self.dw(x))\n",
    "        x = self.act(self.down(self.pw(skip)))\n",
    "        return x, skip\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Upsampling then decoding\"\"\"\n",
    "    def __init__(self, in_c, out_c, mixer_kernel = (7, 7)):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        self.pw = nn.Conv2d(in_c + out_c, out_c,kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_c)\n",
    "        self.dw = AxialDW(out_c, mixer_kernel = (7, 7))\n",
    "        self.act = nn.GELU()\n",
    "        self.pw2 = nn.Conv2d(out_c, out_c, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.act(self.pw2(self.dw(self.bn(self.pw(x)))))\n",
    "        return x\n",
    "    \n",
    "class BottleNeckBlock(nn.Module):\n",
    "    \"\"\"Axial dilated DW convolution\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        gc = dim//4\n",
    "        self.pw1 = nn.Conv2d(dim, gc, kernel_size=1)\n",
    "        self.dw1 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 1)\n",
    "        self.dw2 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 2)\n",
    "        self.dw3 = AxialDW(gc, mixer_kernel = (3, 3), dilation = 3)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(4*gc)\n",
    "        self.pw2 = nn.Conv2d(4*gc, dim, kernel_size=1)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw1(x)\n",
    "        x = torch.cat([x, self.dw1(x), self.dw2(x), self.dw3(x)], 1)\n",
    "        x = self.act(self.pw2(self.bn(x)))\n",
    "        return x\n",
    "\n",
    "class ULite(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"Encoder\"\"\"\n",
    "        # self.conv_in = nn.Conv2d(3, 16, kernel_size=7, padding='same')\n",
    "        self.conv_in = nn.Conv2d(1, 16, kernel_size=7, padding='same')\n",
    "        self.e1 = EncoderBlock(16, 32)\n",
    "        self.e2 = EncoderBlock(32, 64)\n",
    "        self.e3 = EncoderBlock(64, 128)\n",
    "        self.e4 = EncoderBlock(128, 256)\n",
    "        self.e5 = EncoderBlock(256, 512)\n",
    "\n",
    "        \"\"\"Bottle Neck\"\"\"\n",
    "        self.b5 = BottleNeckBlock(512)\n",
    "\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        self.d5 = DecoderBlock(512, 256)\n",
    "        self.d4 = DecoderBlock(256, 128)\n",
    "        self.d3 = DecoderBlock(128, 64)\n",
    "        self.d2 = DecoderBlock(64, 32)\n",
    "        self.d1 = DecoderBlock(32, 16)\n",
    "        self.conv_out = nn.Conv2d(16, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Encoder\"\"\"\n",
    "        x = self.conv_in(x)\n",
    "        x, skip1 = self.e1(x)\n",
    "        x, skip2 = self.e2(x)\n",
    "        x, skip3 = self.e3(x)\n",
    "        x, skip4 = self.e4(x)\n",
    "        x, skip5 = self.e5(x)\n",
    "\n",
    "        \"\"\"BottleNeck\"\"\"\n",
    "        x = self.b5(x)    \n",
    "\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        x = self.d5(x, skip5)\n",
    "        x = self.d4(x, skip4)\n",
    "        x = self.d3(x, skip3)\n",
    "        x = self.d2(x, skip2)\n",
    "        x = self.d1(x, skip1)\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierForULite(nn.Module):\n",
    "\n",
    "    def __init__(self,autoEncoder,nClasses):\n",
    "\n",
    "        super(ClassifierForULite,self).__init__()\n",
    "        self.nClasses = nClasses\n",
    "        \n",
    "        self.autoEncoder = autoEncoder\n",
    "\n",
    "        self.totunecnn1 = nn.Conv2d(512, 16, 3, stride=1, padding=0, bias=False)\n",
    "        self.totunecnn2 = nn.Conv2d(16, 8, 3, stride=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(3)\n",
    "        self.totunelin6 = nn.Linear(8,self.nClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.autoEncoder.conv_in(x)\n",
    "        x, _ = self.autoEncoder.e1(x)\n",
    "        x, _ = self.autoEncoder.e2(x)\n",
    "        x, _ = self.autoEncoder.e3(x)\n",
    "        x, _ = self.autoEncoder.e4(x)\n",
    "        x, _ = self.autoEncoder.e5(x)\n",
    "        x = self.totunecnn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.totunecnn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.totunelin6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "def loadModels():\n",
    "    models = []\n",
    "    model_path = 'C:/Users/fares/OneDrive/Bureau/kaggleBirds/models/BirdClef2024/optunaModels/'\n",
    "    # model_path = '/kaggle/input/optunamodels/pytorch/optunamodels/1/'\n",
    "    pretrainedModel = ULite()\n",
    "    for group in range(2):\n",
    "        for subgroup in range(12):\n",
    "            if (group == 0 and subgroup == 0):\n",
    "                model = ClassifierForULite(pretrainedModel,nClasses=17)\n",
    "            elif (group == 1 and subgroup <= 1):\n",
    "                model = ClassifierForULite(pretrainedModel,nClasses=16)\n",
    "            else:\n",
    "                model = ClassifierForULite(pretrainedModel,nClasses=15)\n",
    "\n",
    "            path = model_path + str(group) + '_' + str(subgroup)           \n",
    "            model.load_state_dict(torch.load(path,map_location=torch.device('cpu')))\n",
    "            models.append(model)\n",
    "\n",
    "    return models\n",
    "\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx\n",
    "import copy\n",
    "\n",
    "def loadQuantizedModels():\n",
    "    models = []\n",
    "    model_path = 'C:/Users/fares/OneDrive/Bureau/kaggleBirds/models/BirdClef2024/optunaModels/'\n",
    "    # model_path = '/kaggle/input/optunamodels/pytorch/optunamodels/1/'\n",
    "    pretrainedModel = ULite()\n",
    "    for group in range(2):\n",
    "        for subgroup in range(12):\n",
    "            if (group == 0 and subgroup == 0):\n",
    "                model1 = ClassifierForULite(pretrainedModel,nClasses=17)\n",
    "            elif (group == 1 and subgroup <= 1):\n",
    "                model1 = ClassifierForULite(pretrainedModel,nClasses=16)\n",
    "            else:\n",
    "                model1 = ClassifierForULite(pretrainedModel,nClasses=15)\n",
    "\n",
    "            path = model_path + str(group) + '_' + str(subgroup)           \n",
    "            model1.load_state_dict(torch.load(path,map_location=torch.device('cpu')))\n",
    "            model = copy.deepcopy(model1)\n",
    "            model.eval()\n",
    "            qconfig = get_default_qconfig(\"x86\")\n",
    "            qconfig_dict = {\"\": qconfig}\n",
    "            model_prepared = prepare_fx(model, qconfig_dict,torch.randn(1, 1, 224, 224))\n",
    "            calibration_data = [torch.randn(1, 1, 224, 224) for _ in range(100)]\n",
    "            for i in range(len(calibration_data)):\n",
    "                model_prepared(calibration_data[i])\n",
    "            model_quantized = convert_fx(copy.deepcopy(model_prepared))\n",
    "            models.append(model_quantized)\n",
    "\n",
    "    return models\n",
    "\n",
    "# def predict(model, nClasses, n_loops, batch_size, path):\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         ypred_test = torch.empty((0,nClasses), dtype = torch.long)\n",
    "#         to = time.time()\n",
    "#         for j in range(n_loops):\n",
    "#             t = torch.load(path + str(j*batch_size) + '.pt' , map_location='cpu').unsqueeze(0).unsqueeze(0)\n",
    "#             for i in range(batch_size - 1):\n",
    "#                     x = torch.load(path + str(j*batch_size + i + 1) + '.pt' , map_location='cpu').unsqueeze(0).unsqueeze(0)\n",
    "#                     t = torch.cat((t,x),dim=0)\n",
    "#             print('time loading : ',(time.time()-to))\n",
    "#             y_hat = model(t)\n",
    "#             ypred_test = torch.cat((ypred_test,y_hat),dim=0)\n",
    "        \n",
    "#         ypred_test = softmax(ypred_test)\n",
    "#         ypred_test.cpu().numpy()\n",
    "    \n",
    "#     return ypred_test\n",
    "\n",
    "def predict(model, tensors, nClasses, n_loops, batch_size, path):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ypred_test = torch.empty((0,nClasses), dtype = torch.long)\n",
    "        for j in range(n_loops):\n",
    "#             t = torch.load(path + str(j*batch_size) + '.pt' , map_location='cpu').unsqueeze(0).unsqueeze(0)\n",
    "#             for i in range(batch_size - 1):\n",
    "#                     x = torch.load(path + str(j*batch_size + i + 1) + '.pt' , map_location='cpu').unsqueeze(0).unsqueeze(0)\n",
    "#                     t = torch.cat((t,x),dim=0)\n",
    "            y_hat = model(tensors[j*batch_size:(j+1)*batch_size])\n",
    "            ypred_test = torch.cat((ypred_test,y_hat),dim=0)\n",
    "        \n",
    "        ypred_test = softmax(ypred_test)\n",
    "#         ypred_test.cpu().numpy()\n",
    "    \n",
    "    return ypred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def predict_for_sample(filename, sample_sub, dataProcessor, models, groups, competition_classes):\n",
    "    s = time.time()\n",
    "    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1] + '_'\n",
    "    probabilities = np.ones((182,),dtype=np.float32)*4.798188e-08\n",
    "    path = '/kaggle/working/chunks/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs('/kaggle/working/chunks/')\n",
    "#     path = 'C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/submission_example/'\n",
    "    chunks = dataProcessor.loadAudio(filename)\n",
    "    sl = time.time()\n",
    "    tensors = torch.empty((0,1,224,224), dtype = torch.float32)\n",
    "    for i,chunk in enumerate(chunks[:-1]):\n",
    "        tensors = torch.cat((tensors,torch.from_numpy(dataProcessor.processChunk(chunk)).unsqueeze(0).unsqueeze(0)),dim=0)\n",
    "#         torch.save(torch.from_numpy(dataProcessor.processChunk(chunk)),'/kaggle/working/chunks/' + str(i) + '.pt')\n",
    "#         torch.save(torch.from_numpy(dataProcessor.processChunk(chunk)),'C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/submission_example/' + str(i) + '.pt')\n",
    "    print('time saving : ',time.time() - sl)\n",
    "    del chunks\n",
    "    print(tensors.shape)\n",
    "\n",
    "#     q_hat = 0.9647314725735\n",
    "\n",
    "    nChunks = len(os.listdir(path))\n",
    "    batch_size = 2\n",
    "    n_loops = nChunks // batch_size\n",
    "\n",
    "    s = time.time()\n",
    "\n",
    "    predictions = []\n",
    "    predictionsGroup0 = []\n",
    "    for _ in range(nChunks-1):\n",
    "        predictions.append([])\n",
    "        predictionsGroup0.append([])\n",
    "\n",
    "    for group in range(2):\n",
    "         for subgroup in range(12):\n",
    "\n",
    "            training_list = groups[group][subgroup]\n",
    "\n",
    "            if (group == 0 and subgroup == 0):\n",
    "                nClasses=17\n",
    "            elif (group == 1 and subgroup <= 1):\n",
    "                nClasses=16\n",
    "            else:\n",
    "                nClasses=15\n",
    "              \n",
    "            modelInd = group*12 + subgroup\n",
    "            models[modelInd].eval()\n",
    "\n",
    "            ypred_test = predict(models[modelInd], tensors, nClasses, n_loops, batch_size, path)\n",
    "\n",
    "            # print('group : ' + str(group) + 'subgroup ' + str(subgroup))\n",
    "\n",
    "            # print('ypred_test. shape : ',ypred_test.shape)\n",
    "\n",
    "            if group == 0:\n",
    "\n",
    "                for i,elem in enumerate(ypred_test):\n",
    "\n",
    "                    for bird_ind in indices_of_top_values(elem, 2):\n",
    "                        predictionsGroup0[i].append(training_list[bird_ind])\n",
    "\n",
    "                    # for classe,soft in enumerate(elem):\n",
    "                    #     if (1 - soft) <= q_hat:\n",
    "                    #         predictionsGroup0[i].append(training_list[classe])\n",
    "\n",
    "            else:\n",
    "\n",
    "                for i,elem in enumerate(ypred_test):\n",
    "\n",
    "                    for bird_ind in indices_of_top_values(elem, 2):\n",
    "                        bird = training_list[bird_ind]\n",
    "                        if bird in predictionsGroup0[i]:\n",
    "                            predictions[i].append(bird)\n",
    "\n",
    "                    # for classe,soft in enumerate(elem):\n",
    "                    #     bird = training_list[classe]\n",
    "                    #     if (1 - soft) <= q_hat and bird in predictionsGroup0[i] :\n",
    "                    #         predictions[i].append(bird)\n",
    "    \n",
    "    # print(predictions)\n",
    "\n",
    "    for i in range(48):\n",
    "        if predictions[i] != []:\n",
    "            for species in predictions[i]:\n",
    "                probabilities[competition_classes.index(species)] = 0.99999999\n",
    "        row_id = file_id + str(5*(i+1))\n",
    "        sample_sub.loc[sample_sub.row_id == row_id, competition_classes] = probabilities\n",
    "        probabilities = np.ones((182,),dtype=np.float32)*4.798188e-08\n",
    "    \n",
    "    print('time processing : ',time.time() - s)\n",
    "    return sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [[['grewar3', 'commyn', 'hoopoe', 'comros', 'eucdov', 'bkwsti', 'barswa', 'graher1', 'bcnher', 'lirplo', 'grywag', 'zitcis1', 'eaywag1', 'rorpar', 'comkin1', 'blrwar1', 'houspa'], ['comgre', 'woosan', 'eurcoo', 'comsan', 'grnsan', 'litgre1', 'commoo3', 'grtdro1', 'bkskit1', 'rewbul', 'wemhar1', 'litegr', 'categr', 'putbab1', 'whiter2'], ['comtai1', 'asikoe2', 'blakit1', 'thbwar1', 'gyhcaf1', 'labcro1', 'comior1', 'whbwat1', 'rerswa1', 'purher1', 'rocpig', 'grnwar1', 'spodov', 'greegr', 'bladro1'], ['brnshr', 'kenplo1', 'brodro1', 'plapri1', 'whtkin2', 'crseag1', 'brnhao1', 'grecou1', 'blhori1', 'blnmon1', 'litswi1', 'ashdro1', 'stbkin1', 'revbul', 'asbfly'], ['rewlap1', 'houcro1', 'ruftre2', 'brwowl1', 'gybpri1', 'pursun4', 'litspi1', 'copbar1', 'gargan', 'laudov1', 'tibfly3', 'brcful1', 'nutman', 'cohcuc1', 'junbab2'], ['piebus1', 'inbrob1', 'ashpri1', 'piekin1', 'whbsho3', 'barfly1', 'rossta2', 'shikra1', 'lblwar1', 'whbwoo2', 'cregos1', 'insbab1', 'sohmyn1', 'goflea1', 'emedov2'], ['grejun2', 'gloibi', 'indpit1', 'ingori1', 'marsan', 'whrmun', 'mawthr1', 'pursun3', 'forwag1', 'junowl1', 'oripip1', 'btbeat1', 'grefla1', 'ashwoo2', 'spepic1'], ['pabflo1', 'whbwag1', 'compea', 'indrob1', 'grbeat1', 'maghor2', 'whcbar1', 'placuc3', 'grenig1', 'orihob2', 'grehor1', 'insowl1', 'whbbul2', 'rufwoo2', 'sbeowl1'], ['gryfra', 'yebbul3', 'lesyel1', 'brakit1', 'purswa3', 'vefnut1', 'bwfshr1', 'plhpar1', 'indrol2', 'lewduc1', 'brfowl1', 'spoowl1', 'bkcbul1', 'sqtbul1', 'lobsun2'], ['whbtre1', 'yebbab1', 'comfla1', 'heswoo1', 'crbsun2', 'tilwar1', 'moipig1', 'aspswi1', 'vehpar1', 'eurbla2', 'sttwoo1', 'malpar1', 'jerbus2', 'rufbab3', 'aspfly1'], ['dafbab1', 'grynig2', 'bkrfla1', 'kerlau2', 'indtit1', 'crfbar1', 'junmyn1', 'smamin1', 'maltro1', 'chbeat1', 'brwjac1', 'plaflo1', 'isbduc1', 'brasta1', 'wynlau1'], ['paisto1', 'redspu1', 'malwoo1', 'nilfly2', 'rutfly6', 'scamin3', 'bncwoo3', 'wbbfly1', 'pomgrp2', 'inpher1', 'blaeag1', 'darter2', 'integr', 'asiope1', 'niwpig1']], [['grewar3', 'hoopoe', 'eucdov', 'barswa', 'bcnher', 'grywag', 'eaywag1', 'comkin1', 'woosan', 'comsan', 'litgre1', 'grtdro1', 'rewbul', 'litegr', 'putbab1', 'blrwar1'], ['commyn', 'comros', 'bkwsti', 'graher1', 'lirplo', 'zitcis1', 'rorpar', 'comgre', 'eurcoo', 'grnsan', 'commoo3', 'bkskit1', 'wemhar1', 'categr', 'whiter2', 'houspa'], ['comtai1', 'blakit1', 'gyhcaf1', 'comior1', 'rerswa1', 'rocpig', 'spodov', 'bladro1', 'kenplo1', 'plapri1', 'crseag1', 'grecou1', 'blnmon1', 'ashdro1', 'revbul'], ['asikoe2', 'thbwar1', 'litgre1', 'whbwat1', 'purher1', 'grnwar1', 'greegr', 'brnshr', 'brodro1', 'whtkin2', 'brnhao1', 'blhori1', 'litswi1', 'stbkin1', 'bladro1'], ['rewlap1', 'ruftre2', 'gybpri1', 'litspi1', 'gargan', 'tibfly3', 'nutman', 'junbab2', 'inbrob1', 'piekin1', 'barfly1', 'shikra1', 'whbwoo2', 'insbab1', 'goflea1'], ['houcro1', 'brwowl1', 'labcro1', 'copbar1', 'laudov1', 'brcful1', 'cohcuc1', 'piebus1', 'ashpri1', 'whbsho3', 'rossta2', 'lblwar1', 'cregos1', 'sohmyn1', 'asbfly'], ['grejun2', 'indpit1', 'marsan', 'mawthr1', 'forwag1', 'oripip1', 'grefla1', 'spepic1', 'whbwag1', 'indrob1', 'maghor2', 'placuc3', 'orihob2', 'insowl1', 'rufwoo2'], ['gloibi', 'ingori1', 'crseag1', 'pursun3', 'junowl1', 'btbeat1', 'ashwoo2', 'pabflo1', 'compea', 'grbeat1', 'whcbar1', 'grenig1', 'grehor1', 'whbbul2', 'junbab2'], ['gryfra', 'lesyel1', 'purswa3', 'bwfshr1', 'indrol2', 'brfowl1', 'bkcbul1', 'lobsun2', 'yebbab1', 'heswoo1', 'tilwar1', 'aspswi1', 'eurbla2', 'malpar1', 'rufbab3'], ['yebbul3', 'brakit1', 'pursun4', 'plhpar1', 'lewduc1', 'spoowl1', 'sqtbul1', 'whbtre1', 'comfla1', 'crbsun2', 'moipig1', 'vehpar1', 'sttwoo1', 'jerbus2', 'emedov2'], ['dafbab1', 'bkrfla1', 'indtit1', 'junmyn1', 'maltro1', 'brwjac1', 'isbduc1', 'wynlau1', 'redspu1', 'nilfly2', 'scamin3', 'wbbfly1', 'inpher1', 'darter2', 'asiope1'], ['grynig2', 'kerlau2', 'barfly1', 'smamin1', 'chbeat1', 'plaflo1', 'brasta1', 'paisto1', 'malwoo1', 'rutfly6', 'bncwoo3', 'pomgrp2', 'blaeag1', 'integr', 'spepic1']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor = melSpectrogram(seconds=5,sr=32000,n_mels=224,hop_length=716)\n",
    "models = loadModels()\n",
    "train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2024/train_metadata.csv\")\n",
    "# train_metadata = pd.read_csv(\"C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/train_metadata.csv\")\n",
    "competition_classes = sorted(train_metadata.primary_label.unique())\n",
    "test_samples = list(glob.glob(\"/kaggle/input/birdclef-2024/unlabeled_soundscapes/*.ogg\")) #/kaggle/input/birdclef-2024/unlabeled_soundscapes #/kaggle/input/birdclef-2024/test_soundscapes\n",
    "# test_samples = list(glob.glob(\"C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/unlabeled_soundscapes_test/*.ogg\"))\n",
    "sample_sub = pd.read_csv(\"/kaggle/input/birdclef-2024/sample_submission.csv\")\n",
    "# sample_sub = pd.read_csv(\"C:/Users/fares/OneDrive/Bureau/kaggleBirds/data/BirdClef2024/sample_submission.csv\")\n",
    "sample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\n",
    "\n",
    "for sample_filename in test_samples:\n",
    "    print(sample_filename)\n",
    "    sample_sub = predict_for_sample(sample_filename, sample_sub, dataProcessor, models, groups, competition_classes)\n",
    "\n",
    "sample_sub.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
